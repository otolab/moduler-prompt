# Experiment configuration for module comparison

models:
  # Local MLX model - for testing text+json output format
  - name: "gemma-12b-local"  # Required: unique name for referencing
    model: "mlx-community/gemma-3-12b-it-qat-4bit"
    provider: "mlx"
    capabilities: ["local", "fast", "tools"]
    priority: 20
    enabled: true

  # Vertex AI Gemini - for testing with structuredOutput support
  - name: "gemini-vertexai"
    model: "gemini-2.0-flash-exp"
    provider: "vertexai"
    capabilities: ["tools", "fast", "japanese"]
    priority: 10
    enabled: true

  # GoogleGenAI Gemini - alternative for testing
  - name: "gemini-googlegenai"
    model: "gemini-2.0-flash-exp"
    provider: "googlegenai"
    capabilities: ["tools", "fast", "japanese"]
    priority: 15
    enabled: false  # Disabled by default

drivers:
  mlx: {}
  vertexai:
    project: "otolab-161708"
    location: "us-central1"
    # Path is resolved relative to this config file
    # Can use ~/ for home directory or absolute paths
    credentialsPath: "~/.nymphish-claude/otolab-vertexai-key.json"
  googlegenai:
    apiKey: "${GOOGLE_API_KEY}"  # Set via environment variable

selection:
  preferLocal: false  # Don't prefer local for experiments
  preferFast: true
  lenient: true

# Evaluation configuration
# Specifies which model to use for AI-based evaluation
evaluation:
  enabled: true
  model: "gemini-vertexai"  # Reference by model name
  # You can also specify model capabilities for selection
  # If model not found, falls back to the best available model

server:
  port: 4100  # Different port to avoid conflict
  host: "127.0.0.1"

logging:
  level: "info"
  request_response_level: "full"

# Modules to test (defined in experiment.config.ts)
modules: []

# Test cases (defined in experiment.config.ts)
testCases: []

# Evaluators (defined in experiment.config.ts)
evaluators: []
