meta:
  model: vertexai:gemini-2.5-flash
  sources:
    - path: model-specific.test.ts
      hash: cb482de0fce423ab27ffb2acf8c8f8f77221962bcb29681860700988c0b9a0b0
  version: 0.0.0
result:
  - |-
    /**
     * モデル固有処理のユニットテスト
     */
    import { createModelSpecificProcessor } from './model-specific.js';
    import type { MlxMessage } from './types.js';

    describe('ModelSpecificProcessor', () => {
  - |2
      describe('Tanuki-8B-dpo-v1 processing', () => {
        const processor = createModelSpecificProcessor('Tanuki-8B-dpo-v1');
        
        test('should add system and user messages', () => {
          const messages: MlxMessage[] = [
            { role: 'user', content: 'Hello' }
          ];
          
          const result = processor.applyModelSpecificProcessing(messages);
          
          expect(result).toHaveLength(3);
          expect(result[0].role).toBe('system');
          expect(result[0].content).toContain('以下は、タスクを説明する指示です');
          expect(result[1].role).toBe('user');
          expect(result[1].content).toBe('Hello');
          expect(result[2].role).toBe('user');
          expect(result[2].content).toContain('systemプロンプトで説明されたタスクを正確に実行し');
        });
      });
  - >2
      describe('CodeLlama processing', () => {
        const processor = createModelSpecificProcessor('mlx-community/CodeLlama-7b');
        
        test('should merge system messages and add user message if needed', () => {
          const messages: MlxMessage[] = [
            { role: 'system', content: 'You are a helpful assistant.' },
            { role: 'assistant', content: 'How can I help?' }
          ];
          
          const result = processor.applyModelSpecificProcessing(messages);
          
          expect(result[result.length - 1].role).toBe('user');
          expect(result[result.length - 1].content).toBe('Read the system prompt and output the appropriate content.');
        });
      });
  - >2
      describe('Gemma-3 processing', () => {
        const processor = createModelSpecificProcessor('mlx-community/gemma-3-2b');
        
        test('should ensure alternating pattern ends with user', () => {
          const messages: MlxMessage[] = [
            { role: 'system', content: 'System message' },
            { role: 'assistant', content: 'Assistant response' }
          ];
          
          const result = processor.applyModelSpecificProcessing(messages);
          
          expect(result[result.length - 1].role).toBe('user');
        });
      });
  - |2
      describe('Unknown model processing', () => {
        const processor = createModelSpecificProcessor('unknown-model');
        
        test('should return messages unchanged', () => {
          const messages: MlxMessage[] = [
            { role: 'user', content: 'Hello' },
            { role: 'assistant', content: 'Hi there!' }
          ];
          
          const result = processor.applyModelSpecificProcessing(messages);
          
          expect(result).toEqual(messages);
        });
      });
  - |2-
      describe('Completion specific processing', () => {
        test('should format llm-jp-3.1 prompt correctly', () => {
          const processor = createModelSpecificProcessor('llm-jp-3.1');
          const prompt = 'Generate a summary';
          
          const result = processor.applyCompletionSpecificProcessing(prompt);
          
          expect(result).toContain('<s>');
          expect(result).toContain('### 指示:');
          expect(result).toContain('Generate a summary');
          expect(result).toContain('### 応答:');
        });

        test('should return prompt unchanged for other models', () => {
          const processor = createModelSpecificProcessor('other-model');
          const prompt = 'Test prompt';
          
          const result = processor.applyCompletionSpecificProcessing(prompt);
          
          expect(result).toBe(prompt);
        });
      });
  - |2-
    
      describe('Generate merged prompt', () => {
        const processor = createModelSpecificProcessor('test-model');
        
        test('should format messages with HTML-style comments', () => {
          const messages: MlxMessage[] = [
            { role: 'system', content: 'System instruction' },
            { role: 'user', content: 'User question' },
            { role: 'assistant', content: 'Assistant response' }
          ];
          
          const result = processor.generateMergedPrompt(messages);
          
          expect(result).toContain('<!-- begin of SYSTEM -->');
          expect(result).toContain('System instruction');
          expect(result).toContain('<!-- end of SYSTEM -->');
          expect(result).toContain('<!-- begin of user -->');
          expect(result).toContain('User question');
          expect(result).toContain('<!-- end of user -->');
        });
      });
    });
